{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPOzpbWuAdUYEhECiTQZqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthKhiriya/Sentiment_Analysis_PRML_Project/blob/main/Obtaining_the_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Obtaining the Dataset**"
      ],
      "metadata": {
        "id": "5MeXQOakAH_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCBAyZBJ_ohv",
        "outputId": "e418f435-c682-447c-d8a1-52e3c2adb44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Installing the kaggle library\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "8BTFpIN7_01N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the API to download the dataset\n",
        "! kaggle datasets download -d abhi8923shriv/sentiment-analysis-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-cHiHIP_7PF",
        "outputId": "1b0e9ab3-4d01-4575-b82b-4fd6af971025"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "dataset = '/content/sentiment-analysis-dataset.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzwR8Z_t_8AD",
        "outputId": "f7c73552-6d42-41df-fee2-2249fb1ea6d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the required libraries and dependencies\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VCzBowYJAB1X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the main dataset and also the train and test set\n",
        "train_given = pd.read_csv('train.csv', encoding='latin-1')\n",
        "test_given = pd.read_csv('test.csv', encoding='latin-1')\n",
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header= None)\n",
        "df = df.drop(labels=0)\n",
        "df.columns = [\"polarity\",\"id\",\"date\",\"query\",\"user\",\"text\"]\n",
        "\n",
        "# This gives the information about our data,  like what are the datatypes of content present in all the columns and also the null count\n",
        "print(df)\n",
        "# Our data has no null values and no duplicates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTCjipRdACiT",
        "outputId": "78a84ef0-c340-4009-9765-b6ec51d9e7b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-14a3abb87616>:4: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header= None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        polarity          id                          date     query  \\\n",
            "1              0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
            "2              0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
            "3              0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "4              0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "5              0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
            "...          ...         ...                           ...       ...   \n",
            "1048568        4  1960186342  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
            "1048569        4  1960186409  Fri May 29 07:33:43 PDT 2009  NO_QUERY   \n",
            "1048570        4  1960186429  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
            "1048571        4  1960186445  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
            "1048572        4  1960186607  Fri May 29 07:33:45 PDT 2009  NO_QUERY   \n",
            "\n",
            "                    user                                               text  \n",
            "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
            "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
            "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
            "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
            "5               joy_wolf                      @Kwesidei not the whole crew   \n",
            "...                  ...                                                ...  \n",
            "1048568  Madelinedugganx           My GrandMa is making Dinenr with my Mum   \n",
            "1048569     OffRoad_Dude  Mid-morning snack time... A bowl of cheese noo...  \n",
            "1048570         Falchion  @ShaDeLa same here  say it like from the Termi...  \n",
            "1048571   jonasobsessedx             @DestinyHope92 im great thaanks  wbuu?  \n",
            "1048572        sugababez               cant wait til her date this weekend   \n",
            "\n",
            "[1048572 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2 : Data Preprocessing**"
      ],
      "metadata": {
        "id": "_ttnEe62v78B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['polarity'].value_counts()\n",
        "\n",
        "# Since value_counts() is showing two different types of 0s so we have to check what is the problem\n",
        "print(df['polarity'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3T8vJntwA6p",
        "outputId": "414ed72b-ed77-47ad-b44d-bf5e76241c46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As the output of unique() function shows that the polarity columns contains two types of 0, integer and string respectively\n",
        "# Now we have to convert the string zero to integer zero, so we will use to_numeric function\n",
        "df['polarity'] = pd.to_numeric(df['polarity'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "df['polarity'] = df['polarity'].astype(str).str.strip().astype(int)"
      ],
      "metadata": {
        "id": "H384Jt04wJwc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us again check if our data has two types of zeroes or not\n",
        "print(df['polarity'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41On-SgZwM01",
        "outputId": "ceefc401-204b-46a3-8fa9-89b4cd9851b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Again checking for the number of positive and negative tweets, this time we get the actual value\n",
        "df['polarity'].value_counts()\n",
        "df['polarity'] = df['polarity'].map({4:1,0:0})\n",
        "df['polarity'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "vDZkBMj0wPfG",
        "outputId": "7982be7a-4fe2-4de8-b926-62e7d5281520"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "polarity\n",
              "0    799996\n",
              "1    248576\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>polarity</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>799996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>248576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now importing some more required dependencies\n",
        "# The re library is for handling regular expressions, like handling links, URLs etc\n",
        "import re\n",
        "import string\n",
        "# The nltk library is for handling the natural language processing tasks such as tokenisation, stemming, removing stopwords etc.\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# This function performs basic tasks for cleaning the data such as lowercasing, URL handling etc.\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()  # Lowercasing\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)  # Remove mentions and hashtags\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    return text.strip()\n",
        "\n",
        "# Save the cleaned text in our dataframe\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Tokenisation - splits the dataset into an array of words(nltk generally performs word tokenisation i.e. seperating words) for better handling of punctuations\n",
        "df['tokens'] = df['cleaned_text'].apply(lambda x: x.split())\n",
        "\n",
        "# Removing all the stopwords because it will not impact the sentiment of the tweet\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
        "\n",
        "# Then stemming(converting a word into its root word e.g. acting, actor to act)\n",
        "stemmer = PorterStemmer()\n",
        "df['stemmed_text'] = df['tokens'].apply(lambda tokens: ' '.join([stemmer.stem(word) for word in tokens]))\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUAyCDaNwSIa",
        "outputId": "931a607d-d556-415b-9e64-497b3205cdce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         polarity          id                          date     query  \\\n",
            "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
            "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
            "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "5               0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
            "...           ...         ...                           ...       ...   \n",
            "1048568         1  1960186342  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
            "1048569         1  1960186409  Fri May 29 07:33:43 PDT 2009  NO_QUERY   \n",
            "1048570         1  1960186429  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
            "1048571         1  1960186445  Fri May 29 07:33:44 PDT 2009  NO_QUERY   \n",
            "1048572         1  1960186607  Fri May 29 07:33:45 PDT 2009  NO_QUERY   \n",
            "\n",
            "                    user                                               text  \\\n",
            "1          scotthamilton  is upset that he can't update his Facebook by ...   \n",
            "2               mattycus  @Kenichan I dived many times for the ball. Man...   \n",
            "3                ElleCTF    my whole body feels itchy and like its on fire    \n",
            "4                 Karoli  @nationwideclass no, it's not behaving at all....   \n",
            "5               joy_wolf                      @Kwesidei not the whole crew    \n",
            "...                  ...                                                ...   \n",
            "1048568  Madelinedugganx           My GrandMa is making Dinenr with my Mum    \n",
            "1048569     OffRoad_Dude  Mid-morning snack time... A bowl of cheese noo...   \n",
            "1048570         Falchion  @ShaDeLa same here  say it like from the Termi...   \n",
            "1048571   jonasobsessedx             @DestinyHope92 im great thaanks  wbuu?   \n",
            "1048572        sugababez               cant wait til her date this weekend    \n",
            "\n",
            "                                              cleaned_text  \\\n",
            "1        is upset that he cant update his facebook by t...   \n",
            "2        i dived many times for the ball managed to sav...   \n",
            "3           my whole body feels itchy and like its on fire   \n",
            "4        no its not behaving at all im mad why am i her...   \n",
            "5                                       not the whole crew   \n",
            "...                                                    ...   \n",
            "1048568            my grandma is making dinenr with my mum   \n",
            "1048569  midmorning snack time a bowl of cheese noodles...   \n",
            "1048570  same here  say it like from the terminiator mo...   \n",
            "1048571                             im great thaanks  wbuu   \n",
            "1048572                cant wait til her date this weekend   \n",
            "\n",
            "                                                    tokens  \\\n",
            "1        [upset, cant, update, facebook, texting, might...   \n",
            "2        [dived, many, times, ball, managed, save, rest...   \n",
            "3                  [whole, body, feels, itchy, like, fire]   \n",
            "4                           [behaving, im, mad, cant, see]   \n",
            "5                                            [whole, crew]   \n",
            "...                                                    ...   \n",
            "1048568                     [grandma, making, dinenr, mum]   \n",
            "1048569  [midmorning, snack, time, bowl, cheese, noodle...   \n",
            "1048570  [say, like, terminiator, movies, comes, like, ...   \n",
            "1048571                         [im, great, thaanks, wbuu]   \n",
            "1048572                   [cant, wait, til, date, weekend]   \n",
            "\n",
            "                                              stemmed_text  \n",
            "1        upset cant updat facebook text might cri resul...  \n",
            "2             dive mani time ball manag save rest go bound  \n",
            "3                          whole bodi feel itchi like fire  \n",
            "4                                    behav im mad cant see  \n",
            "5                                               whole crew  \n",
            "...                                                    ...  \n",
            "1048568                            grandma make dinenr mum  \n",
            "1048569            midmorn snack time bowl chees noodl yum  \n",
            "1048570               say like termini movi come like word  \n",
            "1048571                               im great thaank wbuu  \n",
            "1048572                         cant wait til date weekend  \n",
            "\n",
            "[1048572 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8UbqVwVwqzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
